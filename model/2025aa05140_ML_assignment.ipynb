{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c5dd5846",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 1: Import Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "from xgboost import XGBClassifier\n",
    "import joblib\n",
    "from joblib import dump, load\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    roc_auc_score,\n",
    "    matthews_corrcoef,\n",
    "    classification_report\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "34c96f66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1025, 14)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>125</td>\n",
       "      <td>212</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>168</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>140</td>\n",
       "      <td>203</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>155</td>\n",
       "      <td>1</td>\n",
       "      <td>3.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>145</td>\n",
       "      <td>174</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>125</td>\n",
       "      <td>1</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>61</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>148</td>\n",
       "      <td>203</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>161</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>138</td>\n",
       "      <td>294</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>106</td>\n",
       "      <td>0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n",
       "0   52    1   0       125   212    0        1      168      0      1.0      2   \n",
       "1   53    1   0       140   203    1        0      155      1      3.1      0   \n",
       "2   70    1   0       145   174    0        1      125      1      2.6      0   \n",
       "3   61    1   0       148   203    0        1      161      0      0.0      2   \n",
       "4   62    0   0       138   294    1        1      106      0      1.9      1   \n",
       "\n",
       "   ca  thal  target  \n",
       "0   2     3       0  \n",
       "1   0     3       0  \n",
       "2   0     3       0  \n",
       "3   1     3       0  \n",
       "4   3     2       0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load dataset (update path if needed)\n",
    "data = pd.read_csv(\"heart_full.csv\")\n",
    "print(data.shape)\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a852c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Step 3: Preprocessing\n",
    "X = data.drop('target', axis=1)\n",
    "y = data['target']\n",
    "X=pd.get_dummies(X, drop_first=True) \n",
    "X.fillna(X.mean(), inplace=True) \n",
    "\n",
    "#Train-Test Split\n",
    "\n",
    "\n",
    "# Identify categorical & numerical columns\n",
    "categorical_cols = X.select_dtypes(include=['object']).columns\n",
    "numerical_cols = X.select_dtypes(include=['int64', 'float64']).columns\n",
    "\n",
    "# Preprocessing pipeline\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numerical_cols),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_cols)\n",
    "    ]\n",
    ")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "66f5b46f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 4: Define All 6 Models\n",
    "models = {\n",
    "\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000),\n",
    "\n",
    "    \"Decision Tree\": DecisionTreeClassifier(random_state=42),\n",
    "\n",
    "    \"KNN\": KNeighborsClassifier(n_neighbors=5),\n",
    "\n",
    "    \"Naive Bayes\": GaussianNB(),\n",
    "\n",
    "    \"Random Forest (Ensemble)\": RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "\n",
    "    \"XGBoost (Ensemble)\": XGBClassifier(\n",
    "        use_label_encoder=False,\n",
    "        eval_metric='logloss',\n",
    "        random_state=42\n",
    "    )\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "902c149b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Logistic Regression\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.70      0.78       100\n",
      "           1       0.76      0.91      0.83       105\n",
      "\n",
      "    accuracy                           0.81       205\n",
      "   macro avg       0.82      0.81      0.81       205\n",
      "weighted avg       0.82      0.81      0.81       205\n",
      "\n",
      "\n",
      "Decision Tree\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.99       100\n",
      "           1       1.00      0.97      0.99       105\n",
      "\n",
      "    accuracy                           0.99       205\n",
      "   macro avg       0.99      0.99      0.99       205\n",
      "weighted avg       0.99      0.99      0.99       205\n",
      "\n",
      "\n",
      "KNN\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.87      0.86       100\n",
      "           1       0.87      0.86      0.87       105\n",
      "\n",
      "    accuracy                           0.86       205\n",
      "   macro avg       0.86      0.86      0.86       205\n",
      "weighted avg       0.86      0.86      0.86       205\n",
      "\n",
      "\n",
      "Naive Bayes\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.78      0.82       100\n",
      "           1       0.81      0.88      0.84       105\n",
      "\n",
      "    accuracy                           0.83       205\n",
      "   macro avg       0.83      0.83      0.83       205\n",
      "weighted avg       0.83      0.83      0.83       205\n",
      "\n",
      "\n",
      "Random Forest (Ensemble)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       100\n",
      "           1       1.00      1.00      1.00       105\n",
      "\n",
      "    accuracy                           1.00       205\n",
      "   macro avg       1.00      1.00      1.00       205\n",
      "weighted avg       1.00      1.00      1.00       205\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HP\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:200: UserWarning: [23:41:01] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:782: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "XGBoost (Ensemble)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       100\n",
      "           1       1.00      1.00      1.00       105\n",
      "\n",
      "    accuracy                           1.00       205\n",
      "   macro avg       1.00      1.00      1.00       205\n",
      "weighted avg       1.00      1.00      1.00       205\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Step 5: Train & Evaluate All Models\n",
    "results = []\n",
    "\n",
    "for name, model in models.items():\n",
    "\n",
    "    # Special handling for GaussianNB (needs dense array)\n",
    "    if name == \"Naive Bayes\":\n",
    "        X_train_processed = preprocessor.fit_transform(X_train)\n",
    "        X_test_processed = preprocessor.transform(X_test)\n",
    "\n",
    "        model.fit(X_train_processed, y_train)\n",
    "        joblib.dump((preprocessor, model), f\"bank_model_{name}.pkl\",compress=3)\n",
    "        y_pred = model.predict(X_test_processed)\n",
    "        y_prob = model.predict_proba(X_test_processed)[:, 1]\n",
    "\n",
    "    else:\n",
    "        pipe = Pipeline(steps=[\n",
    "            ('preprocessor', preprocessor),\n",
    "            ('model', model)\n",
    "        ])\n",
    "\n",
    "        pipe.fit(X_train, y_train)\n",
    "        joblib.dump(pipe, f\"bank_model_{name}.pkl\",compress=3)\n",
    "        y_pred = pipe.predict(X_test)\n",
    "        y_prob = pipe.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    auc = roc_auc_score(y_test, y_prob)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    mcc = matthews_corrcoef(y_test, y_pred)\n",
    "\n",
    "\n",
    "    results.append([name, accuracy, auc, precision, recall, f1, mcc])\n",
    "\n",
    "    print(f\"\\n{name}\")\n",
    "    print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dc295a9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>MCC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.809756</td>\n",
       "      <td>0.929810</td>\n",
       "      <td>0.761905</td>\n",
       "      <td>0.914286</td>\n",
       "      <td>0.831169</td>\n",
       "      <td>0.630908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.985366</td>\n",
       "      <td>0.985714</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.971429</td>\n",
       "      <td>0.985507</td>\n",
       "      <td>0.971151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.863415</td>\n",
       "      <td>0.962905</td>\n",
       "      <td>0.873786</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.865385</td>\n",
       "      <td>0.726935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>0.829268</td>\n",
       "      <td>0.904286</td>\n",
       "      <td>0.807018</td>\n",
       "      <td>0.876190</td>\n",
       "      <td>0.840183</td>\n",
       "      <td>0.660163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Random Forest (Ensemble)</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>XGBoost (Ensemble)</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Model  Accuracy       AUC  Precision    Recall  \\\n",
       "0       Logistic Regression  0.809756  0.929810   0.761905  0.914286   \n",
       "1             Decision Tree  0.985366  0.985714   1.000000  0.971429   \n",
       "2                       KNN  0.863415  0.962905   0.873786  0.857143   \n",
       "3               Naive Bayes  0.829268  0.904286   0.807018  0.876190   \n",
       "4  Random Forest (Ensemble)  1.000000  1.000000   1.000000  1.000000   \n",
       "5        XGBoost (Ensemble)  1.000000  1.000000   1.000000  1.000000   \n",
       "\n",
       "         F1       MCC  \n",
       "0  0.831169  0.630908  \n",
       "1  0.985507  0.971151  \n",
       "2  0.865385  0.726935  \n",
       "3  0.840183  0.660163  \n",
       "4  1.000000  1.000000  \n",
       "5  1.000000  1.000000  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Step 6: Compare Model Performance\n",
    "results_df = pd.DataFrame(results, \n",
    "                          columns=[\"Model\", \"Accuracy\", \"AUC\", \"Precision\", \"Recall\", \"F1\", \"MCC\"])\n",
    "\n",
    "results_df.sort_index()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
